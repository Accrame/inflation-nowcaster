{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Scraping Pipeline - Quick Exploration\n",
    "\n",
    "Just checking that the mock scrapers + ETL pipeline work correctly before wiring up Airflow.\n",
    "Obviously these are hardcoded prices so the results don't mean much, but the pipeline is the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from src.scrapers.retailers import AmazonScraper, WalmartScraper, CPI_CATEGORIES\n",
    "from src.models.nowcast import InflationNowcaster, NowcastConfig, CPI_WEIGHTS\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run the mock scrapers\n",
    "\n",
    "Let's pull data from both Amazon and Walmart mock scrapers and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = AmazonScraper()\n",
    "walmart = WalmartScraper()\n",
    "\n",
    "all_products = []\n",
    "\n",
    "for scraper in [amazon, walmart]:\n",
    "    for cat in scraper.get_categories():\n",
    "        products = scraper.scrape_category(cat)\n",
    "        for p in products:\n",
    "            all_products.append(p.model_dump())\n",
    "\n",
    "df = pd.DataFrame(all_products)\n",
    "print(f\"Total products scraped: {len(df)}\")\n",
    "print(f\"Retailers: {df['retailer'].unique()}\")\n",
    "print(f\"Categories: {df['category'].unique()}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic stats\n",
    "\n",
    "ok so the mock data is obviously not real prices but let's see if the pipeline works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Products per retailer ---\")\n",
    "print(df.groupby(\"retailer\")[\"product_id\"].count())\n",
    "print()\n",
    "print(\"--- Products per CPI category ---\")\n",
    "print(df.groupby(\"category\")[\"product_id\"].count())\n",
    "print()\n",
    "print(\"--- Price stats by category ---\")\n",
    "print(df.groupby(\"category\")[\"price\"].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Price distributions by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df[\"category\"].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(categories), figsize=(4 * len(categories), 4), sharey=False)\n",
    "if len(categories) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, cat in zip(axes, categories):\n",
    "    subset = df[df[\"category\"] == cat]\n",
    "    ax.hist(subset[\"price\"], bins=8, edgecolor=\"black\", alpha=0.7)\n",
    "    ax.set_title(cat.title())\n",
    "    ax.set_xlabel(\"Price ($)\")\n",
    "\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "fig.suptitle(\"Price Distribution by CPI Category\", y=1.02, fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# the grocery category has the most variance which makes sense -\n",
    "# bananas at $0.58 vs ground beef at ~$7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulated price time series\n",
    "\n",
    "The scrapers add random noise each time you call them, so let's simulate a few weeks of daily scraping to get a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate 30 days of scraping by calling the scrapers repeatedly\n",
    "np.random.seed(42)\n",
    "ts_rows = []\n",
    "base_date = datetime(2025, 1, 1)\n",
    "\n",
    "for day in range(30):\n",
    "    current_date = base_date + timedelta(days=day)\n",
    "    for scraper in [AmazonScraper(), WalmartScraper()]:\n",
    "        for cat in scraper.get_categories():\n",
    "            for p in scraper.scrape_category(cat):\n",
    "                row = p.model_dump()\n",
    "                row[\"timestamp\"] = current_date\n",
    "                ts_rows.append(row)\n",
    "\n",
    "ts_df = pd.DataFrame(ts_rows)\n",
    "ts_df[\"timestamp\"] = pd.to_datetime(ts_df[\"timestamp\"])\n",
    "print(f\"Generated {len(ts_df)} price observations over 30 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average daily price by category\n",
    "daily_avg = ts_df.groupby([ts_df[\"timestamp\"].dt.date, \"category\"])[\"price\"].mean().reset_index()\n",
    "daily_avg.columns = [\"date\", \"category\", \"avg_price\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for cat in daily_avg[\"category\"].unique():\n",
    "    subset = daily_avg[daily_avg[\"category\"] == cat]\n",
    "    ax.plot(subset[\"date\"], subset[\"avg_price\"], marker=\".\", label=cat, linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Average Price ($)\")\n",
    "ax.set_title(\"Daily Average Price by Category (Mock Data)\")\n",
    "ax.legend(loc=\"best\", fontsize=9)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# recreation (electronics) is way higher than everything else, might want\n",
    "# to normalize or use separate y-axes later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CPI Category Weights\n",
    "\n",
    "These are the BLS basket weights we use for the weighted price index. Housing dominates at 42.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(\n",
    "    [{\"category\": k, \"weight\": v} for k, v in CPI_WEIGHTS.items()]\n",
    ").sort_values(\"weight\", ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.barh(weights_df[\"category\"], weights_df[\"weight\"], color=\"steelblue\", edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Weight\")\n",
    "ax.set_title(\"CPI Basket Weights (BLS Approximation)\")\n",
    "for i, (_, row) in enumerate(weights_df.iterrows()):\n",
    "    ax.text(row[\"weight\"] + 0.005, i, f\"{row['weight']:.1%}\", va=\"center\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run a nowcast computation\n",
    "\n",
    "Let's feed the simulated time series into the `InflationNowcaster` and see what comes out. Since we only have 30 days of mock data with random +/-5% noise, the inflation estimate will basically be noise too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add the 'date' column that the nowcaster expects\n",
    "ts_df[\"date\"] = ts_df[\"timestamp\"].dt.date\n",
    "\n",
    "config = NowcastConfig(\n",
    "    base_period=\"2025-01-01\",\n",
    "    smoothing_window=7,\n",
    "    min_observations=3,  # lowered because mock data is small\n",
    ")\n",
    "nowcaster = InflationNowcaster(config)\n",
    "nowcaster.load_data(ts_df)\n",
    "\n",
    "result = nowcaster.compute_nowcast(as_of_date=datetime(2025, 1, 30))\n",
    "\n",
    "print(f\"Price Index: {result.price_index:.2f}\")\n",
    "print(f\"Inflation Rate: {result.inflation_rate:.2f}%\")\n",
    "print(f\"Observations: {result.observation_count}\")\n",
    "print(f\"Confidence Interval: ({result.confidence_interval[0]:.2f}, {result.confidence_interval[1]:.2f})\")\n",
    "print()\n",
    "print(\"Category breakdown:\")\n",
    "for cat, idx in result.category_indices.items():\n",
    "    contrib = result.category_contributions.get(cat, 0)\n",
    "    print(f\"  {cat:15s} index={idx:6.2f}  contribution={contrib:+.3f}pp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are basically random since the mock scrapers just add uniform noise to hardcoded base prices. In production the idea is that real price changes would show up as actual inflation signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick ARIMA fit on sample data\n",
    "\n",
    "Let's generate a longer fake inflation series and see if ARIMA can at least fit it. Using synthetic data with a slight upward trend + seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.forecast import InflationForecaster, ForecastConfig\n",
    "\n",
    "# generate ~3 years of fake monthly inflation data\n",
    "np.random.seed(123)\n",
    "n_months = 36\n",
    "dates = pd.date_range(\"2022-01-01\", periods=n_months, freq=\"MS\")\n",
    "trend = np.linspace(2.0, 3.5, n_months)\n",
    "seasonal = 0.3 * np.sin(2 * np.pi * np.arange(n_months) / 12)\n",
    "noise = np.random.normal(0, 0.15, n_months)\n",
    "inflation_series = trend + seasonal + noise\n",
    "\n",
    "sample_data = pd.DataFrame({\"date\": dates, \"inflation_rate\": inflation_series})\n",
    "\n",
    "# fit ARIMA\n",
    "fc_config = ForecastConfig(\n",
    "    model_type=\"arima\",\n",
    "    forecast_horizon=6,\n",
    "    auto_order=False,\n",
    "    arima_order=(1, 1, 1),\n",
    "    seasonal_order=(1, 0, 1, 12),\n",
    ")\n",
    "forecaster = InflationForecaster(fc_config)\n",
    "forecaster.fit(sample_data)\n",
    "\n",
    "forecast = forecaster.forecast()\n",
    "print(\"Forecast:\")\n",
    "for d, v in zip(forecast.dates, forecast.values):\n",
    "    print(f\"  {d.strftime('%Y-%m')}: {v:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot historical + forecast\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.plot(sample_data[\"date\"], sample_data[\"inflation_rate\"], \"b-o\", markersize=4, label=\"Historical\")\n",
    "ax.plot(forecast.dates, forecast.values, \"r--s\", markersize=4, label=\"Forecast\")\n",
    "ax.fill_between(forecast.dates, forecast.confidence_lower, forecast.confidence_upper,\n",
    "                color=\"red\", alpha=0.15, label=\"95% CI\")\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Inflation Rate (%)\")\n",
    "ax.set_title(\"ARIMA(1,1,1) Forecast on Synthetic Data\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# obviously this is just fitting noise + trend on fake data, but it shows\n",
    "# the forecaster module works end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Everything seems to work:\n",
    "- Mock scrapers return valid `PriceData` objects with Pydantic validation\n",
    "- CPI category mapping works (Amazon/Walmart categories -> BLS categories)\n",
    "- Nowcaster computes a weighted price index from the scraped data\n",
    "- ARIMA forecaster fits and produces forecasts with confidence intervals\n",
    "\n",
    "Next steps: hook this up to the Airflow DAG and add Great Expectations validation checks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
